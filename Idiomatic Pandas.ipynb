{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idiomatic Pandas\n",
    "\n",
    "¬© MetaSnake 2022, CC BY-NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/dale/.local/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: matplotlib in /home/dale/anaconda3/envs/conda_dale_all/lib/python3.10/site-packages (3.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/dale/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/dale/.local/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/dale/anaconda3/envs/conda_dale_all/lib/python3.10/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dale/.local/lib/python3.10/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/dale/anaconda3/envs/conda_dale_all/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/dale/anaconda3/envs/conda_dale_all/lib/python3.10/site-packages (from matplotlib) (4.39.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/dale/anaconda3/envs/conda_dale_all/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/dale/anaconda3/envs/conda_dale_all/lib/python3.10/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/dale/anaconda3/envs/conda_dale_all/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/dale/anaconda3/envs/conda_dale_all/lib/python3.10/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/dale/anaconda3/envs/conda_dale_all/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dale/anaconda3/envs/conda_dale_all/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit           : 2e218d10984e9919f0296931d92ea851c6a6faf5\n",
      "python           : 3.10.5.final.0\n",
      "python-bits      : 64\n",
      "OS               : Linux\n",
      "OS-release       : 6.2.6-76060206-generic\n",
      "Version          : #202303130630~1683753207~22.04~77c1465 SMP PREEMPT_DYNAMIC Wed M\n",
      "machine          : x86_64\n",
      "processor        : x86_64\n",
      "byteorder        : little\n",
      "LC_ALL           : None\n",
      "LANG             : en_US.UTF-8\n",
      "LOCALE           : en_US.UTF-8\n",
      "\n",
      "pandas           : 1.5.3\n",
      "numpy            : 1.23.5\n",
      "pytz             : 2022.7\n",
      "dateutil         : 2.8.2\n",
      "setuptools       : 66.0.0\n",
      "pip              : 23.0.1\n",
      "Cython           : None\n",
      "pytest           : None\n",
      "hypothesis       : None\n",
      "sphinx           : None\n",
      "blosc            : None\n",
      "feather          : None\n",
      "xlsxwriter       : 3.1.1\n",
      "lxml.etree       : 4.9.2\n",
      "html5lib         : 1.1\n",
      "pymysql          : None\n",
      "psycopg2         : None\n",
      "jinja2           : 3.1.2\n",
      "IPython          : 8.12.0\n",
      "pandas_datareader: None\n",
      "bs4              : 4.12.2\n",
      "bottleneck       : None\n",
      "brotli           : None\n",
      "fastparquet      : None\n",
      "fsspec           : 2023.5.0\n",
      "gcsfs            : None\n",
      "matplotlib       : 3.7.1\n",
      "numba            : None\n",
      "numexpr          : 2.8.4\n",
      "odfpy            : None\n",
      "openpyxl         : 3.1.2\n",
      "pandas_gbq       : None\n",
      "pyarrow          : None\n",
      "pyreadstat       : None\n",
      "pyxlsb           : None\n",
      "s3fs             : None\n",
      "scipy            : 1.10.1\n",
      "snappy           : None\n",
      "sqlalchemy       : 2.0.15\n",
      "tables           : None\n",
      "tabulate         : 0.9.0\n",
      "xarray           : None\n",
      "xlrd             : None\n",
      "xlwt             : None\n",
      "zstandard        : 0.21.0\n",
      "tzdata           : 2023.3\n"
     ]
    }
   ],
   "source": [
    "pd.show_versions()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '*.csv': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data \u001b[39m=\u001b[39m [pd\u001b[39m.\u001b[39mread_csv(f, parse_dates\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m], na_values\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m glob\u001b[39m.\u001b[39mglob(\u001b[39m'\u001b[39m\u001b[39mtweet_activity_metrics___mharrison___*\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m----> 2\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat(data, ignore_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39msort_values(\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m df\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/reshape/concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mobjs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcat\u001b[39m(\n\u001b[1;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[39m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m     copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    158\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m    159\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39m    1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    369\u001b[0m         objs,\n\u001b[1;32m    370\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    371\u001b[0m         ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[1;32m    372\u001b[0m         join\u001b[39m=\u001b[39;49mjoin,\n\u001b[1;32m    373\u001b[0m         keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[1;32m    374\u001b[0m         levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[1;32m    375\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[1;32m    376\u001b[0m         verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[1;32m    377\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    378\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    379\u001b[0m     )\n\u001b[1;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/reshape/concat.py:425\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    422\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(objs)\n\u001b[1;32m    424\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 425\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    427\u001b[0m \u001b[39mif\u001b[39;00m keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(com\u001b[39m.\u001b[39mnot_none(\u001b[39m*\u001b[39mobjs))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "data = [pd.read_csv(f, parse_dates=['time'], na_values='-') for f in glob.glob('tweet_activity_metrics___mharrison___*')]\n",
    "df = pd.concat(data, ignore_index=True).sort_values('time')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('__mharrison__2020-2021.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv('__mharrison__2020-2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/mattharrison/datasets/raw/master/data/__mharrison__2020-2021.csv'\n",
    "df = pd.read_csv(url, parse_dates=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Exercise\n",
    "\n",
    "* Load the data using the cell above.\n",
    "* If you can't do this please alert!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring\n",
    "\n",
    "Definitions\n",
    "\n",
    "* *Impressions* - Number of times people saw the tweet\n",
    "* *Engagements* - Number of \"interactions\" (clicks, replies, retweets, likes)\n",
    "* *Engagement rate* - Engagements divided by impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "with pd.option_context('display.max_columns', 240):\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Exercise\n",
    "* Use `.describe` to view the summary statistics\n",
    "* Use `.corr` to view column correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.memory_usage(deep=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(df\n",
    " .select_dtypes(int).describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(df\n",
    " #.select_dtypes(float)\n",
    " .select_dtypes('float64')\n",
    " .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df\n",
    " .impressions\n",
    " .astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.assign?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(df\n",
    " .assign(impressions=df.impressions.astype(int),\n",
    "         engagements=df.engagements.astype(int)\n",
    "         # lots of this here\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# also note\n",
    "(df\n",
    " .assign(impressions=df.impressions.astype(int),\n",
    "         engagement rate=df.engagements rate.astype(int)\n",
    "         # lots of this here\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fix names\n",
    "(df\n",
    " .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.filter(regex=r'promoted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(df\n",
    " .drop(columns=[c for c in df.columns if 'promoted' in c])\n",
    " .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    " .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be careful with renaming\n",
    "(df\n",
    " .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    " .drop(columns=[c for c in df.columns if 'promoted' in c])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def drop_col(df_, pattern):\n",
    "     return df_.drop(columns=[c for c in df_.columns if pattern in c])\n",
    "\n",
    "(df\n",
    " .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    " #.pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    " .pipe(drop_col, pattern='promoted')\n",
    " .drop(columns=['Tweet_id', 'permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "(df\n",
    " .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    " .pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    " .drop(columns=['Tweet_id', 'permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    " .memory_usage(deep=True)\n",
    " .sum()  # 3 megs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df.pipe?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Cleanup Exercise\n",
    "(Please don't mutate here!)\n",
    "\n",
    "* Use `.loc` to select the *impressions* and *engagement* columns\n",
    "* Use `.drop` to select the *impressions* and *engagement* columns\n",
    "* Use `.rename` to rename *impressions* to *imp* and *engagement* to *eng*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df\n",
    " .loc[:, ['impressions', 'engagements']]\n",
    " .drop(columns=[c for c in df if c no in ['impressions', 'engagements']])\n",
    " .rename(columns={'impressions':'imp', 'engagements':'eng'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok, Types for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "(df\n",
    " .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    " .pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    " .drop(columns=['Tweet_id', 'permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    " .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.iinfo('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for size in ['uint8', 'uint16', 'uint32', 'int8', 'int16', 'int32', 'int64']:\n",
    "    print(f'{size=} {np.iinfo(size)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "(df\n",
    " .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    " .pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    " .drop(columns=['Tweet_id', 'permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    " .assign(impressions=df.impressions.astype('uint32'),\n",
    "         engagements=df.engagements.astype('uint16'),\n",
    "        )\n",
    " .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "for col in df.select_dtypes(float).columns:\n",
    "    print(col)\n",
    "    kwargs[col] = df[col].astype(int)\n",
    "kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use dict comp if you don't want to type every column\n",
    "# assign w/ dict comp. and lambda\n",
    "(df\n",
    " .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    " .pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    " .drop(columns=['Tweet_id', 'permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    " .assign(impressions=df.impressions.astype('uint32'),\n",
    "         engagements=df.engagements.astype('uint16'),\n",
    "         **{c:lambda df_, c=c:df_[c].astype('uint8') for c in ['replies', 'hashtag_clicks', 'follows']}  # less than 255\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# why c=c?\n",
    "(df\n",
    " .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    " .pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    " .drop(columns=['Tweet_id', 'permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    " .assign(impressions=df.impressions.astype('uint32'),\n",
    "         engagements=df.engagements.astype('uint16'),\n",
    "         **{c:lambda df_:df_[c].astype('uint8') for c in ['replies', 'hashtag_clicks', 'follows']},  # less than 255\n",
    "         **{c:lambda df_:df_[c].astype('uint16') for c in ['retweets', 'likes', 'user_profile_clicks', 'url_clicks', \n",
    "                                          'detail_expands', 'media_views', 'media_engagements']}  # less than 65,535\n",
    "        )\n",
    " #.corr()\n",
    " .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/faq/programming.html#why-do-lambdas-defined-in-a-loop-with-different-values-all-return-the-same-result\n",
    "squares = []\n",
    "for x in range(5):\n",
    "    squares.append(lambda: x**2)\n",
    "for s in squares:\n",
    "    print(s())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/faq/programming.html#why-do-lambdas-defined-in-a-loop-with-different-values-all-return-the-same-result\n",
    "squares = []\n",
    "for x in range(5):\n",
    "    squares.append(lambda x=x: x**2)\n",
    "for s in squares:\n",
    "    print(s())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(df\n",
    " .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    " .pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    " .drop(columns=['Tweet_id', 'permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    " .assign(impressions=df.impressions.astype('uint32'),\n",
    "         engagements=df.engagements.astype('uint16'),\n",
    "         **{c:lambda df_, c=c:df_[c].astype('uint8') for c in ['replies', 'hashtag_clicks', 'follows']},  # less than 255\n",
    "         **{c:lambda df_, c=c:df_[c].astype('uint16') for c in ['retweets', 'likes', 'user_profile_clicks', 'url_clicks', \n",
    "                                          'detail_expands', 'media_views', 'media_engagements']}  # less than 65,535\n",
    "        )\n",
    " .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(df\n",
    " .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    " .pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    " .drop(columns=['Tweet_id', 'permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    " .assign(impressions=df.impressions.astype('uint32'),\n",
    "         engagements=df.engagements.astype('uint16'),\n",
    "         **{c:lambda df_, c=c:df_[c].astype('uint8') for c in ['replies', 'hashtag_clicks', 'follows']},  # less than 255\n",
    "         **{c:lambda df_, c=c:df_[c].astype('uint16') for c in ['retweets', 'likes', 'user_profile_clicks', 'url_clicks', \n",
    "                                          'detail_expands', 'media_views', 'media_engagements']}  # less than 65,535\n",
    "         \n",
    "        )\n",
    " .memory_usage(deep=True) \n",
    " .sum()  # was 3 megs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# most is from text\n",
    "(df\n",
    " .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    " .pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    " .drop(columns=['Tweet_id', 'permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    " .assign(impressions=df.impressions.astype('uint32'),\n",
    "         engagements=df.engagements.astype('uint16'),\n",
    "         **{c:lambda df_, c=c:df_[c].astype('uint8') for c in ['replies', 'hashtag_clicks', 'follows']},  # less than 255\n",
    "         **{c:lambda df_, c=c:df_[c].astype('uint16') for c in ['retweets', 'likes', 'user_profile_clicks', 'url_clicks', \n",
    "                                          'detail_expands', 'media_views', 'media_engagements']}  # less than 65,535\n",
    "         \n",
    "        )\n",
    " .memory_usage(deep=True) \n",
    " .pipe(lambda ser: ser/ser.sum()*100)\n",
    "# .sum()  # was 3 megs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# convert first part of permalink to category and add back tweet_id\n",
    "(df\n",
    " .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    " .pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    " .drop(columns=['permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    " .assign(impressions=df.impressions.astype('uint32'),\n",
    "         engagements=df.engagements.astype('uint16'),\n",
    "         **{c:lambda df_, c=c:df_[c].astype('uint8') for c in ['replies', 'hashtag_clicks', 'follows']},  # less than 255\n",
    "         **{c:lambda df_, c=c:df_[c].astype('uint16') for c in ['retweets', 'likes', 'user_profile_clicks', 'url_clicks', \n",
    "                                          'detail_expands', 'media_views', 'media_engagements']},  # less than 65,535\n",
    "         Tweet_permalink=lambda df_: pd.Series('https://twitter.com/__mharrison__/status/', dtype='category', \n",
    "                                               index=df_.index),\n",
    "        )\n",
    " .memory_usage(deep=True) \n",
    " .sum()  # was 3 megs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert first part of permalink to category and add back tweet_id\n",
    "(df\n",
    " .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    " .pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    " .drop(columns=['permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    " .assign(impressions=df.impressions.astype('uint32'),\n",
    "         engagements=df.engagements.astype('uint16'),\n",
    "         **{c:lambda df_, c=c:df_[c].astype('uint8') for c in ['replies', 'hashtag_clicks', 'follows']},  # less than 255\n",
    "         **{c:lambda df_, c=c:df_[c].astype('uint16') for c in ['retweets', 'likes', 'user_profile_clicks', 'url_clicks', \n",
    "                                          'detail_expands', 'media_views', 'media_engagements']},  # less than 65,535\n",
    "         Tweet_permalink=lambda df_: pd.Series('https://twitter.com/__mharrison__/status/', dtype='category', \n",
    "                                               index=df_.index),\n",
    "        )\n",
    " .describe()\n",
    " #.memory_usage(deep=True) \n",
    " #.sum()  # was 3 megs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternate Integer Conversion Exercise\n",
    "(Again, no mutation!)\n",
    "\n",
    "* Use `.select_dtypes` to filter all `int` columns from `df`\n",
    "* Use `.astype` with above to convert all columns to `uint8`\n",
    "* Use `.assign` with above to create new dataframe with updated integer columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Types\n",
    "Can apply similar logic to floats, and strings.\n",
    "\n",
    "Converting \"Tweet_text\" to a category doesn't make sense because it is high cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Uses MORE memory if tweet text is a category!\n",
    "(df\n",
    " .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    " .pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    " .drop(columns=['permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    " .assign(impressions=df.impressions.astype('uint32'),\n",
    "         engagements=df.engagements.astype('uint16'),\n",
    "         **{c:lambda df_, c=c:df_[c].astype('uint8') for c in ['replies', 'hashtag_clicks', 'follows']},  # less than 255\n",
    "         **{c:lambda df_, c=c:df_[c].astype('uint16') for c in ['retweets', 'likes', 'user_profile_clicks', 'url_clicks', \n",
    "                                          'detail_expands', 'media_views', 'media_engagements']},  # less than 65,535\n",
    "         Tweet_permalink=lambda df_: pd.Series('https://twitter.com/__mharrison__/status/', dtype='category', \n",
    "                                               index=df_.index),\n",
    "         Tweet_text=lambda df_:df_.Tweet_text.astype('category')\n",
    "        )\n",
    " .memory_usage(deep=True) \n",
    " .sum()  # was 3 megs\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other types Exercise\n",
    "* Use the `%%timeit` cell magic to see how long it takes to run `.str.lower()` on the original *Tweet permalink* column\n",
    "* Create a new dataframe, `df2`, with our current chain\n",
    "* Use the `%%timeit` cell magic to see how long it takes to run `.str.lower()` on the *df2.Tweet_permalink* column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(df\n",
    " .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    " .pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    " .drop(columns=['permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    " .assign(impressions=df.impressions.astype('uint32'),\n",
    "         engagements=df.engagements.astype('uint16'),\n",
    "         **{c:lambda df_, c=c:df_[c].astype('uint8') for c in ['replies', 'hashtag_clicks', 'follows']},  # less than 255\n",
    "         **{c:lambda df_, c=c:df_[c].astype('uint16') for c in ['retweets', 'likes', 'user_profile_clicks', 'url_clicks', \n",
    "                                          'detail_expands', 'media_views', 'media_engagements']},  # less than 65,535\n",
    "         Tweet_permalink=lambda df_: pd.Series('https://twitter.com/__mharrison__/status/', dtype='category', \n",
    "                                               index=df_.index),\n",
    "        )\n",
    " .time\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert to Local Time (already in UTC)\n",
    "(df\n",
    " .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    " .pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    " .drop(columns=['permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    " .astype({c:'uint8' for c in ['replies', 'hashtag_clicks', 'follows']})  # less than 255)\n",
    " .assign(impressions=df.impressions.astype('uint32'),\n",
    "         engagements=df.engagements.astype('uint16'),\n",
    "         #**{c:lambda df_, c=c:df_[c].astype('uint8') for c in ['replies', 'hashtag_clicks', 'follows']},  # less than 255\n",
    "         **{c:lambda df_, c=c:df_[c].astype('uint16') for c in ['retweets', 'likes', 'user_profile_clicks', 'url_clicks', \n",
    "                                          'detail_expands', 'media_views', 'media_engagements']},  # less than 65,535\n",
    "         Tweet_permalink=lambda df_: pd.Series('https://twitter.com/__mharrison__/status/', dtype='category', \n",
    "                                               index=df_.index),\n",
    "         time=lambda df_: df_.time.dt.tz_convert('America/Denver')\n",
    "        )\n",
    " .time\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates Exercise\n",
    "* Create a series with the months of the *time* column\n",
    "* Convert the *time* column to UTC\n",
    "* Convert the *time* column to `America/New_York`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain\n",
    "\n",
    "Chaining is also called \"flow\" programming. Rather than making intermediate variables, just leverage the fact that most operations return a new object and work on that.\n",
    "\n",
    "The chain should read like a recipe of ordered steps.\n",
    "\n",
    "(BTW, this is actually what we did above.)\n",
    "\n",
    "<div class='alert alert-warning'>\n",
    "    Hint: Leverage <tt>.pipe</tt> if you can't find a way to chain üòâüêºüí™\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to a function\n",
    "def tweak_twitter(df):\n",
    "    return (df\n",
    "     .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    "     .pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    "     .drop(columns=['permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    "     .assign(impressions=df.impressions.astype('uint32'),\n",
    "             engagements=df.engagements.astype('uint16'),\n",
    "             **{c:lambda df_, c=c:df_[c].astype('uint8') for c in ['replies', 'hashtag_clicks', 'follows']},  # less than 255\n",
    "             **{c:lambda df_, c=c:df_[c].astype('uint16') for c in ['retweets', 'likes', 'user_profile_clicks', 'url_clicks', \n",
    "                                              'detail_expands', 'media_views', 'media_engagements']},  # less than 65,535\n",
    "             Tweet_permalink=lambda df_: pd.Series('https://twitter.com/__mharrison__/status/', dtype='category', \n",
    "                                                   index=df_.index),\n",
    "             time=lambda df_: df_.time.dt.tz_convert('America/Denver')\n",
    "            )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would want my notebook to start off like this:\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = [pd.read_csv(f, parse_dates=['time'], na_values='-') for f in glob.glob('tweet_activity_metrics___mharrison___*')]\n",
    "df = pd.concat(data, ignore_index=True).sort_values('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweak_twitter(df):\n",
    "    return (df\n",
    "     .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    "     .pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    "     .drop(columns=['permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    "     .assign(impressions=df.impressions.astype('uint32'),\n",
    "             engagements=df.engagements.astype('uint16'),\n",
    "             **{c:lambda df_, c=c:df_[c].astype('uint8') for c in ['replies', 'hashtag_clicks', 'follows']},  # less than 255\n",
    "             **{c:lambda df_, c=c:df_[c].astype('uint16') for c in ['retweets', 'likes', 'user_profile_clicks', 'url_clicks', \n",
    "                                              'detail_expands', 'media_views', 'media_engagements']},  # less than 65,535\n",
    "             Tweet_permalink=lambda df_: pd.Series('https://twitter.com/__mharrison__/status/', dtype='category', \n",
    "                                                   index=df_.index),\n",
    "             time=lambda df_: df_.time.dt.tz_convert('America/Denver')\n",
    "            )\n",
    "    )\n",
    "twit_df = tweak_twitter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compare with non-chain\n",
    "df1 = df.rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    "keep = [c for c in df1.columns if 'promoted' not in c]\n",
    "df2 = df1[keep]\n",
    "keep2 = [c for c in df2 if c not in ['permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone']]\n",
    "df3 = df2[keep2]\n",
    "imps = df3.impressions.astype('uint32')\n",
    "df3.impressions = imps\n",
    "eng = df3.engagements.astype('uint16')\n",
    "df3['engagements'] = eng\n",
    "df3['replies'] = df3.replies.astype('uint8')\n",
    "df3['hashtag_clicks'] = df3.hashtag_clicks.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# easy to debug\n",
    "#  - assign to var (renamed_df)\n",
    "#  - comment out\n",
    "#  - pipe to display\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "def get_var(df, var_name):\n",
    "    globals()[var_name] = df\n",
    "    return df\n",
    "\n",
    "def tweak_twitter(df):\n",
    "    return (df\n",
    "     .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    "     .pipe(get_var, 'renamed_df')\n",
    "     .pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    "     .drop(columns=['permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    "     .pipe(lambda df_:display(df_) or df_)\n",
    "     .assign(impressions=df.impressions.astype('uint32'),\n",
    "             engagements=df.engagements.astype('uint16'),\n",
    "             **{c:lambda df_, c=c:df_[c].astype('uint8') for c in ['replies', 'hashtag_clicks', 'follows']},  # less than 255\n",
    "             **{c:lambda df_, c=c:df_[c].astype('uint16') for c in ['retweets', 'likes', 'user_profile_clicks', 'url_clicks', \n",
    "                                            'detail_expands', 'media_views', 'media_engagements']},  # less than 65,535\n",
    "             Tweet_permalink=lambda df_: pd.Series('https://twitter.com/__mharrison__/status/', dtype='category', \n",
    "                                                   index=df_.index),\n",
    "            time=lambda df_: df_.time.dt.tz_convert('America/Denver')\n",
    "            )\n",
    "    )\n",
    "twit_df = tweak_twitter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweak_twitter(df):\n",
    "    return (df\n",
    "     .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    "     .pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    "     .drop(columns=['permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    "     .assign(impressions=df.impressions.astype('uint32'),\n",
    "             engagements=df.engagements.astype('uint16'),\n",
    "             **{c:lambda df_, c=c:df_[c].astype('uint8') for c in ['replies', 'hashtag_clicks', 'follows']},  # less than 255\n",
    "             **{c:lambda df_, c=c:df_[c].astype('uint16') for c in ['retweets', 'likes', 'user_profile_clicks', 'url_clicks', \n",
    "                                              'detail_expands', 'media_views', 'media_engagements']},  # less than 65,535\n",
    "             Tweet_permalink=lambda df_: pd.Series('https://twitter.com/__mharrison__/status/', dtype='category', \n",
    "                                                   index=df_.index),\n",
    "             time=lambda df_: df_.time.dt.tz_convert('America/Denver')\n",
    "            )\n",
    "    )\n",
    "twit_df = tweak_twitter(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain Exercise\n",
    "* Use `.pipe` to print the shape of the dataframe after every step in the chain of the `tweak_twitter` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't Mutate\n",
    "\n",
    "> \"you are missing the point, inplace rarely actually does something inplace, you are thinking that you are saving memory but you are not.\"\n",
    ">\n",
    "> **jreback** - Pandas core dev\n",
    "\n",
    "\n",
    "\n",
    "https://github.com/pandas-dev/pandas/issues/16529#issuecomment-676518136\n",
    "\n",
    "* In general, no performance benefits\n",
    "* Prohibits chaining\n",
    "* ``SettingWithCopyWarning`` fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't Apply (if you can)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweak_twitter(df):\n",
    "    return (df\n",
    "     .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    "     .pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    "     .drop(columns=['permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    "     .assign(impressions=df.impressions.astype('uint32'),\n",
    "             engagements=df.engagements.astype('uint16'),\n",
    "             **{c:lambda df_, c=c:df_[c].astype('uint8') for c in ['replies', 'hashtag_clicks', 'follows']},  # less than 255\n",
    "             **{c:lambda df_, c=c:df_[c].astype('uint16') for c in ['retweets', 'likes', 'user_profile_clicks', 'url_clicks', \n",
    "                                              'detail_expands', 'media_views', 'media_engagements']},  # less than 65,535\n",
    "             Tweet_permalink=lambda df_: pd.Series('https://twitter.com/__mharrison__/status/', dtype='category', \n",
    "                                                   index=df_.index),\n",
    "             time=lambda df_: df_.time.dt.tz_convert('America/Denver')\n",
    "            )\n",
    "    )\n",
    "twit_df = tweak_twitter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def to_percent(val):\n",
    "    return val * 100\n",
    "twit_df.engagement_rate.apply(to_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# same result\n",
    "twit_df.engagement_rate * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# however ...\n",
    "twit_df.engagement_rate.apply(to_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "twit_df.engagement_rate * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14X slower!\n",
    "1008 / 71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How would we check if text had unicode?\n",
    "'Hello \\U0001f600'.encode('ascii', errors='replace').decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Hello \\U0001f600'.encode('utf8', errors='replace').decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# story is a little different with text\n",
    "\n",
    "def is_unicode(val):\n",
    "    return val.encode('ascii', errors='replace').decode('ascii') != val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "twit_df.Tweet_text.apply(is_unicode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "twit_df.Tweet_text.str.encode('ascii', errors='replace').str.decode('ascii') == twit_df.Tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "twit_df.Tweet_text.str.startswith('@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startswith_at(txt):\n",
    "    return txt.startswith('@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "twit_df.Tweet_text.apply(startswith_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweak_twitter(df):\n",
    "    return (df\n",
    "     .rename(columns=lambda col_name: col_name.replace(' ', '_'))\n",
    "     .pipe(lambda df_: df_.drop(columns=[c for c in df_.columns if 'promoted' in c]))\n",
    "     .drop(columns=['permalink_clicks', 'app_opens', 'app_installs', 'email_tweet', 'dial_phone'])\n",
    "     .assign(impressions=df.impressions.astype('uint32'),\n",
    "             engagements=df.engagements.astype('uint16'),\n",
    "             **{c:lambda df_, c=c:df_[c].astype('uint8') for c in ['replies', 'hashtag_clicks', 'follows']},  # less than 255\n",
    "             **{c:lambda df_, c=c:df_[c].astype('uint16') for c in ['retweets', 'likes', 'user_profile_clicks', 'url_clicks', \n",
    "                                              'detail_expands', 'media_views', 'media_engagements']},  # less than 65,535\n",
    "             Tweet_permalink=lambda df_: pd.Series('https://twitter.com/__mharrison__/status/', dtype='category', \n",
    "                                                   index=df_.index),\n",
    "             time=lambda df_: df_.time.dt.tz_convert('America/Denver'),\n",
    "             is_reply=lambda df_: df_.Tweet_text.str.startswith('@'),\n",
    "             length=lambda df_:df_.Tweet_text.str.len(),\n",
    "             num_words=lambda df_:df_.Tweet_text.str.split().apply(len),\n",
    "             is_unicode=lambda df_:df_.Tweet_text.str.encode('ascii', errors='replace').str.decode('ascii') != df_.Tweet_text,\n",
    "             hour=lambda df_:df_.time.dt.hour,\n",
    "             dom=lambda df_:df_.time.dt.day,  #day of month\n",
    "             dow=lambda df_:df_.time.dt.dayofweek,  #day of week\n",
    "             at_tweet=lambda df_:df_.Tweet_text.str.contains('@'),\n",
    "             has_newlines=lambda df_:df_.Tweet_text.str.contains('\\n'),\n",
    "             num_lines=lambda df_:df_.Tweet_text.str.count('\\n'),\n",
    "             num_mentions=lambda df_:df_.Tweet_text.str.count('@'),\n",
    "             has_hashtag=lambda df_:df_.Tweet_text.str.count('#'),\n",
    "            )\n",
    "    )\n",
    "twit_df = tweak_twitter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Exercise\n",
    "* Calculate engagement ratio by dividing *engagements* by *impressions*\n",
    "* Calculate engagement ratio 2 by dividing the sum of *replies*, *retweets*, *likes*, *user_profile_clicks*, and *detail_expands* by *impressions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(twit_df\n",
    " .groupby(twit_df.time.dt.year)\n",
    " .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twit_df.groupby(twit_df.time.dt.year).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(twit_df\n",
    " .groupby(twit_df.time.dt.year)\n",
    " .impressions\n",
    " .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "(twit_df\n",
    " .groupby(twit_df.time.dt.year)\n",
    " .mean()\n",
    " [['impressions', 'replies']]  # index operation with a list inside \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "(twit_df\n",
    " .groupby(twit_df.time.dt.year)\n",
    " [['impressions', 'replies']]  # index operation with a list inside \n",
    "  .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_df.Tweet_text.str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_df.time.dt.year.rename('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(twit_df\n",
    " .groupby([twit_df.time.dt.year.rename('year'), twit_df.time.dt.month.rename('month')])\n",
    " [['impressions', 'replies']]\n",
    " .mean()\n",
    " #.round(2)\n",
    " .style\n",
    " .format({'replies': '{:.3f}', 'impressions': '{:e}'})\n",
    " \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(twit_df\n",
    " .groupby([twit_df.time.dt.year, twit_df.time.dt.month])\n",
    " [['impressions', 'replies']]\n",
    " #.mean()\n",
    " .median()\n",
    " .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(twit_df\n",
    " #.groupby([twit_df.time.dt.year, twit_df.time.dt.month])\n",
    " .groupby(pd.Grouper(key='time', freq='2M'))\n",
    " [['impressions', 'replies']]\n",
    " #.mean()\n",
    " .median()\n",
    " .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(twit_df\n",
    " #.groupby([twit_df.time.dt.year, twit_df.time.dt.month])\n",
    " .groupby(pd.Grouper(key='time', freq='2w'))\n",
    " [['impressions', 'replies']]\n",
    " .mean()\n",
    " .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(twit_df\n",
    " #.groupby([twit_df.time.dt.year, twit_df.time.dt.month])\n",
    " .groupby(pd.Grouper(key='time', freq='7d5h'))\n",
    " [['impressions', 'replies']]\n",
    " .mean()\n",
    " #.plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(twit_df\n",
    " #.groupby([twit_df.time.dt.year, twit_df.time.dt.month])\n",
    " .groupby([pd.Grouper(key='time', freq='7d5h'), 'is_unicode'])\n",
    " [['impressions', 'replies']]\n",
    " .mean()\n",
    " #.plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# multiple aggregates\n",
    "def second_to_last(ser):\n",
    "    try:\n",
    "        return ser.iloc[-2]\n",
    "    except IndexError:\n",
    "        return 0\n",
    "\n",
    "(twit_df\n",
    " .groupby([pd.Grouper(key='time', freq='7d5h'), 'is_unicode'])\n",
    " [['impressions', 'replies']]\n",
    " .agg(['mean', 'median', second_to_last])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# multiple aggregates\n",
    "\n",
    "(twit_df\n",
    " .groupby([pd.Grouper(key='time', freq='7d5h'), 'is_unicode'])\n",
    " [['impressions', 'replies']]\n",
    " .agg(['mean', 'median', second_to_last])\n",
    " .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# multiple aggregates\n",
    "\n",
    "(twit_df\n",
    " .groupby([pd.Grouper(key='time', freq='7d'), 'is_unicode'])\n",
    " [['impressions', 'replies']]\n",
    " .agg(['mean', 'median', second_to_last])\n",
    " .unstack()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# multiple aggregates\n",
    "\n",
    "(twit_df\n",
    " .groupby([pd.Grouper(key='time', freq='7d'), 'is_unicode'])\n",
    " [['impressions', 'replies']]\n",
    " .agg(['mean', 'median', second_to_last])\n",
    " .unstack()\n",
    " .impressions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# multiple aggregates\n",
    "(twit_df\n",
    " .groupby([pd.Grouper(key='time', freq='7d'), 'is_unicode'])\n",
    " [['impressions', 'replies']]\n",
    " .agg(['mean', 'median', second_to_last])\n",
    " .unstack()\n",
    " .impressions\n",
    " ['mean']  # note have to use index syntax here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# multiple aggregates\n",
    "(twit_df\n",
    " .groupby([pd.Grouper(key='time', freq='7d'), 'is_unicode'])\n",
    " [['impressions', 'replies']]\n",
    " .agg(['mean', 'median', second_to_last])\n",
    " .unstack()\n",
    " .impressions\n",
    " .mean  # note have to use index syntax here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# multiple aggregates\n",
    "(twit_df\n",
    " .groupby([pd.Grouper(key='time', freq='7d'), 'is_unicode'])\n",
    " [['impressions', 'replies']]\n",
    " .agg(['mean', 'median', second_to_last])\n",
    " .unstack()\n",
    " .impressions\n",
    " ['mean']\n",
    " .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# multiple aggregates\n",
    "# dealing with missing values\n",
    "(twit_df\n",
    " .groupby([pd.Grouper(key='time', freq='7d'), 'is_unicode'])\n",
    " [['impressions', 'replies']]\n",
    " .agg(['mean', 'median', second_to_last])\n",
    " .unstack()\n",
    " .impressions\n",
    " ['mean']\n",
    " #.fillna(0)\n",
    " #.interpolate()\n",
    " #.bfill()\n",
    " #.dropna()\n",
    " .loc['2021/07':'2021/08']\n",
    " #.plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# multiple aggregates\n",
    "(twit_df\n",
    " .groupby([pd.Grouper(key='time', freq='3d'), 'is_unicode'])\n",
    " [['impressions', 'replies']]\n",
    " .agg(['mean', 'median', second_to_last])\n",
    " .unstack()\n",
    " .impressions\n",
    " ['mean']\n",
    " .interpolate()\n",
    " .rolling(7)\n",
    " .mean()\n",
    " .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# named aggregation\n",
    "\n",
    "(twit_df\n",
    " .groupby([pd.Grouper(key='time', freq='M'), 'is_unicode'])\n",
    " .agg(total_views=('impressions', 'sum'),\n",
    "     mean_views=('impressions', 'mean'),\n",
    "     profile_clicks=('user_profile_clicks', lambda ser: ser.sum()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# named aggregation - fails with resample\n",
    "\n",
    "(twit_df\n",
    " #.groupby([pd.Grouper(key='time', freq='M'), 'is_unicode'])\n",
    " .set_index('time')\n",
    " .resample('M')\n",
    " .agg(total_views=('impressions', 'sum'),\n",
    "     mean_views=('impressions', 'mean'),\n",
    "     profile_clicks=('user_profile_clicks', lambda ser: ser.sum()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# named aggregation\n",
    "\n",
    "(twit_df\n",
    " .groupby([pd.Grouper(key='time', freq='M'), 'is_unicode'])\n",
    " .agg(total_views=('impressions', 'sum'),\n",
    "     mean_views=('impressions', 'mean'),\n",
    "     profile_clicks=('user_profile_clicks', lambda ser: ser.sum()))\n",
    " .unstack()\n",
    " .profile_clicks\n",
    " .plot()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Exercise\n",
    "* What were the total impressions for each year?\n",
    "* What were the total impressions for each month?\n",
    "* Plot the previous\n",
    "* What were the total impressions for unicode and non-unicode tweets for each month?\n",
    "* Plot the previous\n",
    "* What were the total impressions for reply and non-reply tweets for each month?\n",
    "* Plot the previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* Correct types save space and enable convenient math, string, and date functionality\n",
    "* Chaining operations will:\n",
    "   * Make code readable\n",
    "   * Remove bugs\n",
    "   * Easier to debug\n",
    "* Don't mutate (there's no point). Embrace chaining.\n",
    "* ``.apply`` is slow for math\n",
    "* Aggregations are powerful. Play with them until they make sense\n",
    "\n",
    "Connect with me on LinkedIn or Twitter (@\\_\\_mharrison\\_\\_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
